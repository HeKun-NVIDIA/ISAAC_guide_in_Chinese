# 在机器人应用Deepstream

## 技术
[NVIDIA DeepStream SDK](https://developer.nvidia.com/deepstream-sdk) 为基于 AI 的视频和图像感知以及多传感器处理提供了完整的流分析工具包。 DeepStream 是 NVIDIA Metropolis 不可或缺的一部分，NVIDIA Metropolis 是构建端到端服务和解决方案的平台，可将像素和传感器数据转化为可操作的见解。

Isaac SDK 附带各种针对机器人用例量身定制的媒体采集、发布、编码、解码、推断和处理功能。 然而，多媒体支持不是机器人框架的主要职责。 机器人集成的大量多媒体需求使得直接支持变得困难，因此与作为 Isaac 组件的 DeepStream 集成提供了一个解决方案。

**注意**

NVIDIA DeepStream SDK 基于开源 GStreamer 库：一种基于管道的多媒体框架，可将各种媒体处理系统连接在一起。 GStreamer 本身基于 GLib：一组低级库，用于为 C、可移植性包装器、执行循环和接口提供数据结构处理。 访问 [GStreamer 开源多媒体框架网站](https://gstreamer.freedesktop.org/)，了解详细信息和对该框架的贡献。


## 组件
开源 GStreamer 框架和 [NVIDIA DeepStream SDK 作为 Isaac 组件](https://docs.nvidia.com/isaac/doc/component_api.html#isaac-deepstream-pipeline)的内部集成允许您重用它们的多媒体处理功能集合。 Isaac 和 DeepStream 产品在机器人和媒体用例方面自然互补。

GPU 加速的 DeepStream 元素可以用作 GStreamer 管道定义的一部分。 DeepStream 可以与 Jetson Nano 和 Xavier 平台的 Jetson JetPack 安装程序一起安装。 按照 [DeepStream 安装说明](https://docs.nvidia.com/metropolis/deepstream/dev-guide/index.html)使它们的元素在您的主机系统上可用。

**注意**

Isaac 不分发 DeepStream 或 GStreamer。 您必须选择要安装的模块并遵守其许可证。

媒体管道通过命名的 appsink 和 appsrc 元素连接到 Isaac 引擎，分别用于接收和传输。 组件管道配置参数允许您使用任何配置和元素启动任何 GStreamer 管道字符串。 管道可能包含零个或多个应用程序源或接收器。 不包含应用程序源或接收器的管道由 Isaac 管理但不共享数据，这对于机器人应用程序的间接多媒体支持很有用。

应用程序元素支持具有等效 Isaac protobuffer 消息的功能、格式和内存模型，详见下表。 使用适当的 videoconvert 和 `nvvideoconvert` 元素和 caps 过滤器以实现兼容性。 必须明确定义能力。

|能力|格式|消息|
|----|----|----|
|video/x-raw|RGB|[ImageProto](https://docs.nvidia.com/isaac/doc/message_api.html#imageproto)|

DeepStream组件向其他Isaac组件传输消息的获取时间戳为发布时刻的节点时间。

该组件将一个 Isaac 调度程序线程池注入到 GStreamer 管道中。 线程池遵循[Isaac线程规则](https://docs.nvidia.com/isaac/doc/scheduler/scheduler.html#scheduler)和[GStreamer线程规则](https://gstreamer.freedesktop.org/documentation/application-development/advanced/threads.html?gi-language=c#scheduling-in-gstreamer)：

* 该组件为管道主循环运行单个服务作业。

* 管道为其元素使用一个或多个作业。

* 一个或多个元素可以在单个作业中运行。

* 一个元素可以使用多个作业。

* 这些元素分别对上游或下游线程使用基于推或拉的调度。

* 这些工作使用最早的最后期限优先政策。

* 每个作业都有一个执行组配置。

* 管道分支可以配置为在具有队列元素的不同线程上运行。

* 作业统计信息在调度程序报告中报告。

以下是 `gstreamer_pipeline_multi` 应用程序的示例作业统计报告。 管道由三个简单的独立分支组成，它们依次运行三个作业。
```bash
|=========================================================================================|
|                            Job Statistics Report (blocking)                             |
|=========================================================================================|
| Name                       |          Job Mode | Count | Time (Median - 90% - Max) [ms] |
|-----------------------------------------------------------------------------------------|
|         DeepStream Service | Blocking One Shot |     1 | 32816.30 | 32816.30 | 32816.30 |
| DeepStream Pipeline Thread | Blocking One Shot |     1 | 32814.40 | 32814.40 | 32814.40 |
| DeepStream Pipeline Thread | Blocking One Shot |     1 | 32814.42 | 32814.42 | 32814.42 |
| DeepStream Pipeline Thread | Blocking One Shot |     1 | 32814.52 | 32814.52 | 32814.52 |
|=========================================================================================|
```

## 工具
[gst-inspect-1.0](https://gstreamer.freedesktop.org/documentation/tools/gst-inspect.html?gi-language=c) 命令行工具允许您查看主机上可用的元素：

```bash
$ gst-inspect-1.0
video4linux2:  v4l2src: Video (video4linux2) Source
video4linux2:  v4l2sink: Video (video4linux2) Sink
video4linux2:  v4l2radio: Radio (video4linux2) Tuner
video4linux2:  v4l2deviceprovider (GstDeviceProviderFactory)
dtls:  dtlsenc: DTLS Encoder
[...]
Total count: 265 plugins, 1420 features
```

[gst-launch-1.0](https://gstreamer.freedesktop.org/documentation/tools/gst-launch.html?gi-language=c) 命令行工具允许您构建和运行 `GStreamer` 管道。 通过将 GST_DEBUG 环境变量设置为 `0`（无调试输出）和 `8`（完整内存转储）之间的类别级别，为 GStreamer 启用调试输出。 `4` 级的信息通常是最实用的。

```bash
$ export GST_DEBUG=4
# Your application will now output debug information when you run it.
```
通过将 `GST_DEBUG_DUMP_DOT_DIR` 环境变量设置为现有的可写目录路径来获取管道图。 使用点工具生成可视图像。

```bash
$ sudo apt install graphviz
$ export GST_DEBUG_DUMP_DOT_DIR=/tmp
# Running your application will generate a FILENAME.dot file in the /tmp folder which can be
# converted by the following command:
$ dot -Tpng /tmp/FILENAME.dot > pipeline.png
```

例子
以下示例显示了来自 `GStreamer FAQ` 的测试视频，其中启用了调试信息、图形绘制和详细信息：

```bash
$ GST_DEBUG=4 GST_DEBUG_DUMP_DOT_DIR=. gst-launch-1.0 -v \
  videotestsrc ! videoconvert ! autovideosink
```
原始的 GStreamer 示例已更改为演示如何在 Isaac 应用程序中集成 GStreamer 管道。 Isaac 示例显示了如何将管道媒体导入或导出到应用程序配置中可用的 Isaac 通信通道。

管道有两个容器：一个测试视频源通过一个应用程序接收器进入 Isaac，一个应用程序源将视频流暴露给一个显示视频接收器。 应用程序元素的功能是有限的。 因此，videoconvert 元素确保源和接收器元素都支持 RGB 原始格式。 因此，管道更改为以下内容：

```bash
videotestsrc ! video/x-raw,format=RGB ! videoconvert ! appsink name=to_isaac

appsrc name=from_isaac ! video/x-raw,format=RGB ! videoconvert ! autovideosink
```
![](https://docs.nvidia.com/isaac/_images/example_pipeline.jpg)

Isaac应用实例
下面是一个最小的 Isaac 应用程序，它通过 Isaac 将视频从接收器传递到源：

```json
{
  "name": "example_pipeline_app",
  "modules": [
    "deepstream",
  ],
  "graph": {
    "nodes": [
      {
        "name": "deepstream",
        "components": [
          {
            "name": "message_ledger",
            "type": "isaac::alice::MessageLedger"
          },
          {
            "name": "pipeline",
            "type": "isaac::deepstream::Pipeline"
          }
        ]
      }
    ],
    "edges": [
      {
        "source": "deepstream/pipeline/to_isaac",
        "target": "deepstream/pipeline/from_isaac"
      }
    ]
  },
  "config": {
    "deepstream": {
      "pipeline": {
        "pipeline": "videotestsrc ! video/x-raw,format=RGB ! videoconvert ! appsink name=to_isaac  appsrc name=from_isaac ! video/x-raw,format=RGB ! videoconvert ! autovideosink"
      }
    }
  }
}
```


使用视频测试源可视化应用程序接收器在 Isaac WebSight 中如下所示：

![](https://docs.nvidia.com/isaac/_images/example_output.jpg)

packages/deepstream/apps 文件夹中提供了其他演示应用程序：

<table class="docutils align-default">
<colgroup>
<col style="width: 34%" />
<col style="width: 66%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Application Name</p></th>
<th class="head"><p>Demonstration</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>gstreamer_pipeline</p></td>
<td><p>Trivial GStreamer video test source pipeline</p></td>
</tr>
<tr class="row-odd"><td><p>gstreamer_pipeline_distributed_a</p></td>
<td><p>Acquire and publish MPEG-4 compressed video over UDP transport</p></td>
</tr>
<tr class="row-even"><td><p>gstreamer_pipeline_distributed_b</p></td>
<td><p>Receive MPEG-4 compressed video over UDP transport</p></td>
</tr>
<tr class="row-odd"><td><p>gstreamer_pipeline_external</p></td>
<td><p>Isaac-managed external media pipelines</p></td>
</tr>
<tr class="row-even"><td><p>gstreamer_pipeline_multi</p></td>
<td><p>Multiple video pipelines in a single component</p></td>
</tr>
<tr class="row-odd"><td><p>logitech_c920pro_cpu</p></td>
<td><p>USB connected, V4L2 interfaced, H.264 compressed, CPU
decoded camera</p></td>
</tr>
<tr class="row-even"><td><p>philips_spc1330nc</p></td>
<td><p>Trivial USB connected, V4L2 interfaced raw, uncompressed camera</p></td>
</tr>
<tr class="row-odd"><td><p>sony_snchmx70</p></td>
<td><p>Ethernet IP/RTSP transported, H.264 compressed camera</p></td>
</tr>
</tbody>
</table>





































